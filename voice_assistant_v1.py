#!/usr/bin/env python3
"""
Voice Assistant Prototype v1
Prosty test: Enter ‚Üí nagraj ‚Üí STT ‚Üí Claude ‚Üí TTS ‚Üí play
"""

import sounddevice as sd
import soundfile as sf
import numpy as np
import requests
import json
from faster_whisper import WhisperModel
import sys
import os

# =============================================================================
# KONFIGURACJA
# =============================================================================

# Audio settings
SAMPLE_RATE = 16000  # 16kHz dla Whisper
RECORD_DURATION = 5  # sekundy nagrywania
AUDIO_FILE = "recorded_audio.wav"
OUTPUT_AUDIO = "response_audio.wav"

# Clawdbot API
CLAWDBOT_URL = "http://localhost:18789"  # Zmie≈Ñ je≈õli potrzeba
CLAWDBOT_TOKEN = "bb283f9626e7a84f6b29bb7c284c2da3e01c64fa39c45d89"  # Z Twojego configu

# Whisper model (tiny/base/small/medium)
WHISPER_MODEL = "base"  # base to kompromis miƒôdzy szybko≈õciƒÖ a jako≈õciƒÖ

# =============================================================================
# FUNKCJE
# =============================================================================

def record_audio(duration=RECORD_DURATION, sample_rate=SAMPLE_RATE):
    """Nagraj audio z mikrofonu"""
    print(f"üé§ Nagrywam przez {duration} sekund...")
    audio = sd.rec(int(duration * sample_rate), 
                   samplerate=sample_rate, 
                   channels=1, 
                   dtype='int16')
    sd.wait()
    print("‚úì Nagranie zako≈Ñczone")
    return audio

def save_audio(audio, filename=AUDIO_FILE, sample_rate=SAMPLE_RATE):
    """Zapisz audio do pliku WAV"""
    sf.write(filename, audio, sample_rate)
    print(f"‚úì Zapisano do {filename}")

def transcribe_audio(audio_file, model):
    """Transkrypcja audio ‚Üí tekst (Whisper)"""
    print("üî§ Transkrybujƒô audio...")
    segments, info = model.transcribe(audio_file, language="pl")
    
    text = ""
    for segment in segments:
        text += segment.text + " "
    
    text = text.strip()
    print(f"‚úì Rozpoznano: \"{text}\"")
    return text

def ask_claude(text):
    """Wy≈õlij pytanie do Claude przez Clawdbot API (OpenAI-compatible)"""
    print("ü§ñ Pytam Claude...")
    
    url = f"{CLAWDBOT_URL}/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {CLAWDBOT_TOKEN}",
        "Content-Type": "application/json",
        "x-clawdbot-agent-id": "main"
    }
    payload = {
        "model": "clawdbot",
        "messages": [
            {"role": "user", "content": text}
        ],
        "stream": False
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        data = response.json()
        
        # OpenAI format: data.choices[0].message.content
        answer = data.get("choices", [{}])[0].get("message", {}).get("content", "")
        
        if not answer:
            answer = "Przepraszam, otrzyma≈Çem pustƒÖ odpowied≈∫."
        
        print(f"‚úì Claude odpowiedzia≈Ç: \"{answer[:100]}...\"")
        return answer
        
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd API: {e}")
        return "Przepraszam, nie mogƒô teraz odpowiedzieƒá."

def text_to_speech(text, output_file=OUTPUT_AUDIO):
    """Generuj mowƒô z tekstu (LuxTTS)"""
    print("üîä Generujƒô mowƒô...")
    
    # TODO: Integracja z LuxTTS
    # Na razie placeholder - wymaga inicjalizacji modelu
    
    # from zipvoice.luxvoice import LuxTTS
    # lux_tts = LuxTTS('YatharthS/LuxTTS', device='cpu', threads=2)
    # encoded_prompt = lux_tts.encode_prompt('reference_voice.wav', rms=0.01)
    # final_wav = lux_tts.generate_speech(text, encoded_prompt, num_steps=4)
    # sf.write(output_file, final_wav.numpy().squeeze(), 48000)
    
    print("‚ö†Ô∏è  LuxTTS not implemented yet - u≈ºywam placeholder")
    # Tymczasowo: zwr√≥ƒá info ≈ºe trzeba dodaƒá TTS
    return None

def play_audio(audio_file, sample_rate=48000):
    """Odtw√≥rz audio przez g≈Ço≈õnik"""
    print("üîä Odtwarzam odpowied≈∫...")
    data, sr = sf.read(audio_file)
    sd.play(data, sr)
    sd.wait()
    print("‚úì Odtworzono")

# =============================================================================
# G≈Å√ìWNA PƒòTLA
# =============================================================================

def main():
    print("=" * 60)
    print("Voice Assistant Prototype v1")
    print("=" * 60)
    print()
    
    # Inicjalizacja Whisper
    print("≈Åadujƒô model Whisper...")
    whisper_model = WhisperModel(WHISPER_MODEL, device="cpu", compute_type="int8")
    print("‚úì Whisper gotowy")
    print()
    
    # TODO: Inicjalizacja LuxTTS
    # lux_tts = ...
    
    while True:
        print("-" * 60)
        input("Naci≈õnij ENTER aby nagraƒá pytanie (Ctrl+C aby wyj≈õƒá)...")
        
        try:
            # 1. Nagraj
            audio = record_audio()
            save_audio(audio)
            
            # 2. STT (Whisper)
            text = transcribe_audio(AUDIO_FILE, whisper_model)
            
            if not text:
                print("‚ö†Ô∏è  Nie rozpoznano tekstu, spr√≥buj ponownie")
                continue
            
            # 3. LLM (Claude)
            response = ask_claude(text)
            
            # 4. TTS (LuxTTS)
            audio_file = text_to_speech(response)
            
            # 5. Play
            if audio_file and os.path.exists(audio_file):
                play_audio(audio_file)
            else:
                print(f"üìù Odpowied≈∫ (tekst): {response}")
            
            print()
            
        except KeyboardInterrupt:
            print("\n\nüëã Do zobaczenia!")
            break
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()
